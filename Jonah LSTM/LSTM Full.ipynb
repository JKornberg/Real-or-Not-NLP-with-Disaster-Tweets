{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = '../Data/Processed/'\n",
    "destination_folder = '../Data/Processed/LSTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Preliminaries\n",
    "\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields\n",
    "\n",
    "id_field = Field(sequential=False, use_vocab=False, batch_first=True,dtype=torch.int)\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(tokenize='spacy', lower=True, include_lengths=True, batch_first=True)\n",
    "fields = [('target', label_field),('text', text_field),('id', id_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='valid.csv', test='test.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=32, sort_key=lambda x: len(x.text),\n",
    "                            device=device, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=32, sort_key=lambda x: len(x.text),\n",
    "                            device=device, sort=True, sort_within_batch=True)\n",
    "\n",
    "# Vocabulary\n",
    "\n",
    "text_field.build_vocab(train, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, dimension=128):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(len(text_field.vocab), 300)\n",
    "        self.dimension = dimension\n",
    "        self.lstm = nn.LSTM(input_size=300,\n",
    "                            hidden_size=dimension,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc = nn.Linear(2*dimension, 1)\n",
    "\n",
    "    def forward(self, text, text_len):\n",
    "\n",
    "        text_emb = self.embedding(text)\n",
    "\n",
    "        packed_input = pack_padded_sequence(text_emb, text_len, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n",
    "        out_reverse = output[:, 0, self.dimension:]\n",
    "        out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
    "        text_fea = self.drop(out_reduced)\n",
    "\n",
    "        text_fea = self.fc(text_fea)\n",
    "        text_fea = torch.squeeze(text_fea, 1)\n",
    "        text_out = torch.sigmoid(text_fea)\n",
    "\n",
    "        return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Functions\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for (labels, (text, text_len), ids), _ in train_loader:           \n",
    "            labels = labels.to(device)\n",
    "            text = text.to(device)\n",
    "            text_len = text_len.to(device)\n",
    "            output = model(text, text_len)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                  # validation loop\n",
    "                    for (labels, (text, text_len), ids),_ in valid_loader:\n",
    "                        labels = labels.to(device)\n",
    "                        text = text.to(device)\n",
    "                        text_len = text_len.to(device)\n",
    "                        output = model(text, text_len)\n",
    "                        loss = criterion(output, labels)\n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "                    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [83/1670], Train Loss: 0.6595, Valid Loss: 0.6152\n",
      "Model saved to ==> ../Data/Processed/LSTM/model.pt\n",
      "Model saved to ==> ../Data/Processed/LSTM/metrics.pt\n",
      "Epoch [1/10], Step [166/1670], Train Loss: 0.6044, Valid Loss: 0.5513\n",
      "Model saved to ==> ../Data/Processed/LSTM/model.pt\n",
      "Model saved to ==> ../Data/Processed/LSTM/metrics.pt\n",
      "Epoch [2/10], Step [249/1670], Train Loss: 0.4845, Valid Loss: 0.5158\n",
      "Model saved to ==> ../Data/Processed/LSTM/model.pt\n",
      "Model saved to ==> ../Data/Processed/LSTM/metrics.pt\n",
      "Epoch [2/10], Step [332/1670], Train Loss: 0.4471, Valid Loss: 0.5038\n",
      "Model saved to ==> ../Data/Processed/LSTM/model.pt\n",
      "Model saved to ==> ../Data/Processed/LSTM/metrics.pt\n",
      "Epoch [3/10], Step [415/1670], Train Loss: 0.3461, Valid Loss: 0.5017\n",
      "Model saved to ==> ../Data/Processed/LSTM/model.pt\n",
      "Model saved to ==> ../Data/Processed/LSTM/metrics.pt\n",
      "Epoch [3/10], Step [498/1670], Train Loss: 0.3142, Valid Loss: 0.5446\n",
      "Epoch [4/10], Step [581/1670], Train Loss: 0.2405, Valid Loss: 0.5643\n",
      "Epoch [4/10], Step [664/1670], Train Loss: 0.2123, Valid Loss: 0.6429\n",
      "Epoch [5/10], Step [747/1670], Train Loss: 0.1498, Valid Loss: 0.6942\n",
      "Epoch [5/10], Step [830/1670], Train Loss: 0.1328, Valid Loss: 0.7388\n",
      "Epoch [6/10], Step [913/1670], Train Loss: 0.1021, Valid Loss: 0.8023\n",
      "Epoch [6/10], Step [996/1670], Train Loss: 0.0809, Valid Loss: 0.8079\n",
      "Epoch [7/10], Step [1079/1670], Train Loss: 0.0695, Valid Loss: 0.9747\n",
      "Epoch [7/10], Step [1162/1670], Train Loss: 0.0620, Valid Loss: 0.8969\n",
      "Epoch [8/10], Step [1245/1670], Train Loss: 0.0609, Valid Loss: 1.0184\n",
      "Epoch [8/10], Step [1328/1670], Train Loss: 0.0516, Valid Loss: 0.9108\n",
      "Epoch [9/10], Step [1411/1670], Train Loss: 0.0501, Valid Loss: 1.0632\n",
      "Epoch [9/10], Step [1494/1670], Train Loss: 0.0453, Valid Loss: 0.9939\n",
      "Epoch [10/10], Step [1577/1670], Train Loss: 0.0447, Valid Loss: 1.0939\n",
      "Epoch [10/10], Step [1660/1670], Train Loss: 0.0419, Valid Loss: 1.0286\n",
      "Model saved to ==> ../Data/Processed/LSTM/metrics.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "model = LSTM().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(model=model, optimizer=optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== ../Data/Processed/metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def evaluate_to_df(model, test_loader, threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_id = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for ((text, text_len),idn), _ in test_loader:     \n",
    "            text = text.to(device)\n",
    "            text_len = text_len.to(device)\n",
    "            output = model(text, text_len)\n",
    "\n",
    "            output = (output > threshold).int()\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_id.extend(idn.tolist())\n",
    "    submission_df = pd.DataFrame()\n",
    "    submission_df['prediction'] = y_pred\n",
    "    submission_df['id'] = y_id\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== ../Data/Processed/model.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTM:\n\tMissing key(s) in state_dict: \"embedding.weight\", \"lstm.weight_ih_l0\", \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"lstm.weight_ih_l0_reverse\", \"lstm.weight_hh_l0_reverse\", \"lstm.bias_ih_l0_reverse\", \"lstm.bias_hh_l0_reverse\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.bert.embeddings.word_embeddings.weight\", \"encoder.bert.embeddings.position_embeddings.weight\", \"encoder.bert.embeddings.token_type_embeddings.weight\", \"encoder.bert.embeddings.LayerNorm.weight\", \"encoder.bert.embeddings.LayerNorm.bias\", \"encoder.bert.encoder.layer.0.attention.self.query.weight\", \"encoder.bert.encoder.layer.0.attention.self.query.bias\", \"encoder.bert.encoder.layer.0.attention.self.key.weight\", \"encoder.bert.encoder.layer.0.attention.self.key.bias\", \"encoder.bert.encoder.layer.0.attention.self.value.weight\", \"encoder.bert.encoder.layer.0.attention.self.value.bias\", \"encoder.bert.encoder.layer.0.attention.output.dense.weight\", \"encoder.bert.encoder.layer.0.attention.output.dense.bias\", \"encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.0.intermediate.dense.weight\", \"encoder.bert.encoder.layer.0.intermediate.dense.bias\", \"encoder.bert.encoder.layer.0.output.dense.weight\", \"encoder.bert.encoder.layer.0.output.dense.bias\", \"encoder.bert.encoder.layer.0.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.0.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.1.attention.self.query.weight\", \"encoder.bert.encoder.layer.1.attention.self.query.bias\", \"encoder.bert.encoder.layer.1.attention.self.key.weight\", \"encoder.bert.encoder.layer.1.attention.self.key.bias\", \"encoder.bert.encoder.layer.1.attention.self.value.weight\", \"encoder.bert.encoder.layer.1.attention.self.value.bias\", \"encoder.bert.encoder.layer.1.attention.output.dense.weight\", \"encoder.bert.encoder.layer.1.attention.output.dense.bias\", \"encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.1.intermediate.dense.weight\", \"encoder.bert.encoder.layer.1.intermediate.dense.bias\", \"encoder.bert.encoder.layer.1.output.dense.weight\", \"encoder.bert.encoder.layer.1.output.dense.bias\", \"encoder.bert.encoder.layer.1.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.1.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.2.attention.self.query.weight\", \"encoder.bert.encoder.layer.2.attention.self.query.bias\", \"encoder.bert.encoder.layer.2.attention.self.key.weight\", \"encoder.bert.encoder.layer.2.attention.self.key.bias\", \"encoder.bert.encoder.layer.2.attention.self.value.weight\", \"encoder.bert.encoder.layer.2.attention.self.value.bias\", \"encoder.bert.encoder.layer.2.attention.output.dense.weight\", \"encoder.bert.encoder.layer.2.attention.output.dense.bias\", \"encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.2.intermediate.dense.weight\", \"encoder.bert.encoder.layer.2.intermediate.dense.bias\", \"encoder.bert.encoder.layer.2.output.dense.weight\", \"encoder.bert.encoder.layer.2.output.dense.bias\", \"encoder.bert.encoder.layer.2.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.2.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.3.attention.self.query.weight\", \"encoder.bert.encoder.layer.3.attention.self.query.bias\", \"encoder.bert.encoder.layer.3.attention.self.key.weight\", \"encoder.bert.encoder.layer.3.attention.self.key.bias\", \"encoder.bert.encoder.layer.3.attention.self.value.weight\", \"encoder.bert.encoder.layer.3.attention.self.value.bias\", \"encoder.bert.encoder.layer.3.attention.output.dense.weight\", \"encoder.bert.encoder.layer.3.attention.output.dense.bias\", \"encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.3.intermediate.dense.weight\", \"encoder.bert.encoder.layer.3.intermediate.dense.bias\", \"encoder.bert.encoder.layer.3.output.dense.weight\", \"encoder.bert.encoder.layer.3.output.dense.bias\", \"encoder.bert.encoder.layer.3.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.3.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.4.attention.self.query.weight\", \"encoder.bert.encoder.layer.4.attention.self.query.bias\", \"encoder.bert.encoder.layer.4.attention.self.key.weight\", \"encoder.bert.encoder.layer.4.attention.self.key.bias\", \"encoder.bert.encoder.layer.4.attention.self.value.weight\", \"encoder.bert.encoder.layer.4.attention.self.value.bias\", \"encoder.bert.encoder.layer.4.attention.output.dense.weight\", \"encoder.bert.encoder.layer.4.attention.output.dense.bias\", \"encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.4.intermediate.dense.weight\", \"encoder.bert.encoder.layer.4.intermediate.dense.bias\", \"encoder.bert.encoder.layer.4.output.dense.weight\", \"encoder.bert.encoder.layer.4.output.dense.bias\", \"encoder.bert.encoder.layer.4.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.4.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.5.attention.self.query.weight\", \"encoder.bert.encoder.layer.5.attention.self.query.bias\", \"encoder.bert.encoder.layer.5.attention.self.key.weight\", \"encoder.bert.encoder.layer.5.attention.self.key.bias\", \"encoder.bert.encoder.layer.5.attention.self.value.weight\", \"encoder.bert.encoder.layer.5.attention.self.value.bias\", \"encoder.bert.encoder.layer.5.attention.output.dense.weight\", \"encoder.bert.encoder.layer.5.attention.output.dense.bias\", \"encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.5.intermediate.dense.weight\", \"encoder.bert.encoder.layer.5.intermediate.dense.bias\", \"encoder.bert.encoder.layer.5.output.dense.weight\", \"encoder.bert.encoder.layer.5.output.dense.bias\", \"encoder.bert.encoder.layer.5.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.5.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.6.attention.self.query.weight\", \"encoder.bert.encoder.layer.6.attention.self.query.bias\", \"encoder.bert.encoder.layer.6.attention.self.key.weight\", \"encoder.bert.encoder.layer.6.attention.self.key.bias\", \"encoder.bert.encoder.layer.6.attention.self.value.weight\", \"encoder.bert.encoder.layer.6.attention.self.value.bias\", \"encoder.bert.encoder.layer.6.attention.output.dense.weight\", \"encoder.bert.encoder.layer.6.attention.output.dense.bias\", \"encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.6.intermediate.dense.weight\", \"encoder.bert.encoder.layer.6.intermediate.dense.bias\", \"encoder.bert.encoder.layer.6.output.dense.weight\", \"encoder.bert.encoder.layer.6.output.dense.bias\", \"encoder.bert.encoder.layer.6.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.6.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.7.attention.self.query.weight\", \"encoder.bert.encoder.layer.7.attention.self.query.bias\", \"encoder.bert.encoder.layer.7.attention.self.key.weight\", \"encoder.bert.encoder.layer.7.attention.self.key.bias\", \"encoder.bert.encoder.layer.7.attention.self.value.weight\", \"encoder.bert.encoder.layer.7.attention.self.value.bias\", \"encoder.bert.encoder.layer.7.attention.output.dense.weight\", \"encoder.bert.encoder.layer.7.attention.output.dense.bias\", \"encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.7.intermediate.dense.weight\", \"encoder.bert.encoder.layer.7.intermediate.dense.bias\", \"encoder.bert.encoder.layer.7.output.dense.weight\", \"encoder.bert.encoder.layer.7.output.dense.bias\", \"encoder.bert.encoder.layer.7.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.7.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.8.attention.self.query.weight\", \"encoder.bert.encoder.layer.8.attention.self.query.bias\", \"encoder.bert.encoder.layer.8.attention.self.key.weight\", \"encoder.bert.encoder.layer.8.attention.self.key.bias\", \"encoder.bert.encoder.layer.8.attention.self.value.weight\", \"encoder.bert.encoder.layer.8.attention.self.value.bias\", \"encoder.bert.encoder.layer.8.attention.output.dense.weight\", \"encoder.bert.encoder.layer.8.attention.output.dense.bias\", \"encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.8.intermediate.dense.weight\", \"encoder.bert.encoder.layer.8.intermediate.dense.bias\", \"encoder.bert.encoder.layer.8.output.dense.weight\", \"encoder.bert.encoder.layer.8.output.dense.bias\", \"encoder.bert.encoder.layer.8.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.8.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.9.attention.self.query.weight\", \"encoder.bert.encoder.layer.9.attention.self.query.bias\", \"encoder.bert.encoder.layer.9.attention.self.key.weight\", \"encoder.bert.encoder.layer.9.attention.self.key.bias\", \"encoder.bert.encoder.layer.9.attention.self.value.weight\", \"encoder.bert.encoder.layer.9.attention.self.value.bias\", \"encoder.bert.encoder.layer.9.attention.output.dense.weight\", \"encoder.bert.encoder.layer.9.attention.output.dense.bias\", \"encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.9.intermediate.dense.weight\", \"encoder.bert.encoder.layer.9.intermediate.dense.bias\", \"encoder.bert.encoder.layer.9.output.dense.weight\", \"encoder.bert.encoder.layer.9.output.dense.bias\", \"encoder.bert.encoder.layer.9.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.9.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.10.attention.self.query.weight\", \"encoder.bert.encoder.layer.10.attention.self.query.bias\", \"encoder.bert.encoder.layer.10.attention.self.key.weight\", \"encoder.bert.encoder.layer.10.attention.self.key.bias\", \"encoder.bert.encoder.layer.10.attention.self.value.weight\", \"encoder.bert.encoder.layer.10.attention.self.value.bias\", \"encoder.bert.encoder.layer.10.attention.output.dense.weight\", \"encoder.bert.encoder.layer.10.attention.output.dense.bias\", \"encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.10.intermediate.dense.weight\", \"encoder.bert.encoder.layer.10.intermediate.dense.bias\", \"encoder.bert.encoder.layer.10.output.dense.weight\", \"encoder.bert.encoder.layer.10.output.dense.bias\", \"encoder.bert.encoder.layer.10.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.10.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.11.attention.self.query.weight\", \"encoder.bert.encoder.layer.11.attention.self.query.bias\", \"encoder.bert.encoder.layer.11.attention.self.key.weight\", \"encoder.bert.encoder.layer.11.attention.self.key.bias\", \"encoder.bert.encoder.layer.11.attention.self.value.weight\", \"encoder.bert.encoder.layer.11.attention.self.value.bias\", \"encoder.bert.encoder.layer.11.attention.output.dense.weight\", \"encoder.bert.encoder.layer.11.attention.output.dense.bias\", \"encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.11.intermediate.dense.weight\", \"encoder.bert.encoder.layer.11.intermediate.dense.bias\", \"encoder.bert.encoder.layer.11.output.dense.weight\", \"encoder.bert.encoder.layer.11.output.dense.bias\", \"encoder.bert.encoder.layer.11.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.11.output.LayerNorm.bias\", \"encoder.bert.pooler.dense.weight\", \"encoder.bert.pooler.dense.bias\", \"encoder.classifier.weight\", \"encoder.classifier.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-82b7048dceff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mload_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestination_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/model.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-63f76c5eeb1b>\u001b[0m in \u001b[0;36mload_checkpoint\u001b[1;34m(load_path, model, optimizer)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Model loaded from <== {load_path}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optimizer_state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\opencv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 845\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTM:\n\tMissing key(s) in state_dict: \"embedding.weight\", \"lstm.weight_ih_l0\", \"lstm.weight_hh_l0\", \"lstm.bias_ih_l0\", \"lstm.bias_hh_l0\", \"lstm.weight_ih_l0_reverse\", \"lstm.weight_hh_l0_reverse\", \"lstm.bias_ih_l0_reverse\", \"lstm.bias_hh_l0_reverse\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.bert.embeddings.word_embeddings.weight\", \"encoder.bert.embeddings.position_embeddings.weight\", \"encoder.bert.embeddings.token_type_embeddings.weight\", \"encoder.bert.embeddings.LayerNorm.weight\", \"encoder.bert.embeddings.LayerNorm.bias\", \"encoder.bert.encoder.layer.0.attention.self.query.weight\", \"encoder.bert.encoder.layer.0.attention.self.query.bias\", \"encoder.bert.encoder.layer.0.attention.self.key.weight\", \"encoder.bert.encoder.layer.0.attention.self.key.bias\", \"encoder.bert.encoder.layer.0.attention.self.value.weight\", \"encoder.bert.encoder.layer.0.attention.self.value.bias\", \"encoder.bert.encoder.layer.0.attention.output.dense.weight\", \"encoder.bert.encoder.layer.0.attention.output.dense.bias\", \"encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.0.intermediate.dense.weight\", \"encoder.bert.encoder.layer.0.intermediate.dense.bias\", \"encoder.bert.encoder.layer.0.output.dense.weight\", \"encoder.bert.encoder.layer.0.output.dense.bias\", \"encoder.bert.encoder.layer.0.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.0.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.1.attention.self.query.weight\", \"encoder.bert.encoder.layer.1.attention.self.query.bias\", \"encoder.bert.encoder.layer.1.attention.self.key.weight\", \"encoder.bert.encoder.layer.1.attention.self.key.bias\", \"encoder.bert.encoder.layer.1.attention.self.value.weight\", \"encoder.bert.encoder.layer.1.attention.self.value.bias\", \"encoder.bert.encoder.layer.1.attention.output.dense.weight\", \"encoder.bert.encoder.layer.1.attention.output.dense.bias\", \"encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.1.intermediate.dense.weight\", \"encoder.bert.encoder.layer.1.intermediate.dense.bias\", \"encoder.bert.encoder.layer.1.output.dense.weight\", \"encoder.bert.encoder.layer.1.output.dense.bias\", \"encoder.bert.encoder.layer.1.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.1.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.2.attention.self.query.weight\", \"encoder.bert.encoder.layer.2.attention.self.query.bias\", \"encoder.bert.encoder.layer.2.attention.self.key.weight\", \"encoder.bert.encoder.layer.2.attention.self.key.bias\", \"encoder.bert.encoder.layer.2.attention.self.value.weight\", \"encoder.bert.encoder.layer.2.attention.self.value.bias\", \"encoder.bert.encoder.layer.2.attention.output.dense.weight\", \"encoder.bert.encoder.layer.2.attention.output.dense.bias\", \"encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.2.intermediate.dense.weight\", \"encoder.bert.encoder.layer.2.intermediate.dense.bias\", \"encoder.bert.encoder.layer.2.output.dense.weight\", \"encoder.bert.encoder.layer.2.output.dense.bias\", \"encoder.bert.encoder.layer.2.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.2.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.3.attention.self.query.weight\", \"encoder.bert.encoder.layer.3.attention.self.query.bias\", \"encoder.bert.encoder.layer.3.attention.self.key.weight\", \"encoder.bert.encoder.layer.3.attention.self.key.bias\", \"encoder.bert.encoder.layer.3.attention.self.value.weight\", \"encoder.bert.encoder.layer.3.attention.self.value.bias\", \"encoder.bert.encoder.layer.3.attention.output.dense.weight\", \"encoder.bert.encoder.layer.3.attention.output.dense.bias\", \"encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.3.intermediate.dense.weight\", \"encoder.bert.encoder.layer.3.intermediate.dense.bias\", \"encoder.bert.encoder.layer.3.output.dense.weight\", \"encoder.bert.encoder.layer.3.output.dense.bias\", \"encoder.bert.encoder.layer.3.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.3.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.4.attention.self.query.weight\", \"encoder.bert.encoder.layer.4.attention.self.query.bias\", \"encoder.bert.encoder.layer.4.attention.self.key.weight\", \"encoder.bert.encoder.layer.4.attention.self.key.bias\", \"encoder.bert.encoder.layer.4.attention.self.value.weight\", \"encoder.bert.encoder.layer.4.attention.self.value.bias\", \"encoder.bert.encoder.layer.4.attention.output.dense.weight\", \"encoder.bert.encoder.layer.4.attention.output.dense.bias\", \"encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.4.intermediate.dense.weight\", \"encoder.bert.encoder.layer.4.intermediate.dense.bias\", \"encoder.bert.encoder.layer.4.output.dense.weight\", \"encoder.bert.encoder.layer.4.output.dense.bias\", \"encoder.bert.encoder.layer.4.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.4.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.5.attention.self.query.weight\", \"encoder.bert.encoder.layer.5.attention.self.query.bias\", \"encoder.bert.encoder.layer.5.attention.self.key.weight\", \"encoder.bert.encoder.layer.5.attention.self.key.bias\", \"encoder.bert.encoder.layer.5.attention.self.value.weight\", \"encoder.bert.encoder.layer.5.attention.self.value.bias\", \"encoder.bert.encoder.layer.5.attention.output.dense.weight\", \"encoder.bert.encoder.layer.5.attention.output.dense.bias\", \"encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.5.intermediate.dense.weight\", \"encoder.bert.encoder.layer.5.intermediate.dense.bias\", \"encoder.bert.encoder.layer.5.output.dense.weight\", \"encoder.bert.encoder.layer.5.output.dense.bias\", \"encoder.bert.encoder.layer.5.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.5.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.6.attention.self.query.weight\", \"encoder.bert.encoder.layer.6.attention.self.query.bias\", \"encoder.bert.encoder.layer.6.attention.self.key.weight\", \"encoder.bert.encoder.layer.6.attention.self.key.bias\", \"encoder.bert.encoder.layer.6.attention.self.value.weight\", \"encoder.bert.encoder.layer.6.attention.self.value.bias\", \"encoder.bert.encoder.layer.6.attention.output.dense.weight\", \"encoder.bert.encoder.layer.6.attention.output.dense.bias\", \"encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.6.intermediate.dense.weight\", \"encoder.bert.encoder.layer.6.intermediate.dense.bias\", \"encoder.bert.encoder.layer.6.output.dense.weight\", \"encoder.bert.encoder.layer.6.output.dense.bias\", \"encoder.bert.encoder.layer.6.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.6.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.7.attention.self.query.weight\", \"encoder.bert.encoder.layer.7.attention.self.query.bias\", \"encoder.bert.encoder.layer.7.attention.self.key.weight\", \"encoder.bert.encoder.layer.7.attention.self.key.bias\", \"encoder.bert.encoder.layer.7.attention.self.value.weight\", \"encoder.bert.encoder.layer.7.attention.self.value.bias\", \"encoder.bert.encoder.layer.7.attention.output.dense.weight\", \"encoder.bert.encoder.layer.7.attention.output.dense.bias\", \"encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.7.intermediate.dense.weight\", \"encoder.bert.encoder.layer.7.intermediate.dense.bias\", \"encoder.bert.encoder.layer.7.output.dense.weight\", \"encoder.bert.encoder.layer.7.output.dense.bias\", \"encoder.bert.encoder.layer.7.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.7.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.8.attention.self.query.weight\", \"encoder.bert.encoder.layer.8.attention.self.query.bias\", \"encoder.bert.encoder.layer.8.attention.self.key.weight\", \"encoder.bert.encoder.layer.8.attention.self.key.bias\", \"encoder.bert.encoder.layer.8.attention.self.value.weight\", \"encoder.bert.encoder.layer.8.attention.self.value.bias\", \"encoder.bert.encoder.layer.8.attention.output.dense.weight\", \"encoder.bert.encoder.layer.8.attention.output.dense.bias\", \"encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.8.intermediate.dense.weight\", \"encoder.bert.encoder.layer.8.intermediate.dense.bias\", \"encoder.bert.encoder.layer.8.output.dense.weight\", \"encoder.bert.encoder.layer.8.output.dense.bias\", \"encoder.bert.encoder.layer.8.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.8.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.9.attention.self.query.weight\", \"encoder.bert.encoder.layer.9.attention.self.query.bias\", \"encoder.bert.encoder.layer.9.attention.self.key.weight\", \"encoder.bert.encoder.layer.9.attention.self.key.bias\", \"encoder.bert.encoder.layer.9.attention.self.value.weight\", \"encoder.bert.encoder.layer.9.attention.self.value.bias\", \"encoder.bert.encoder.layer.9.attention.output.dense.weight\", \"encoder.bert.encoder.layer.9.attention.output.dense.bias\", \"encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.9.intermediate.dense.weight\", \"encoder.bert.encoder.layer.9.intermediate.dense.bias\", \"encoder.bert.encoder.layer.9.output.dense.weight\", \"encoder.bert.encoder.layer.9.output.dense.bias\", \"encoder.bert.encoder.layer.9.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.9.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.10.attention.self.query.weight\", \"encoder.bert.encoder.layer.10.attention.self.query.bias\", \"encoder.bert.encoder.layer.10.attention.self.key.weight\", \"encoder.bert.encoder.layer.10.attention.self.key.bias\", \"encoder.bert.encoder.layer.10.attention.self.value.weight\", \"encoder.bert.encoder.layer.10.attention.self.value.bias\", \"encoder.bert.encoder.layer.10.attention.output.dense.weight\", \"encoder.bert.encoder.layer.10.attention.output.dense.bias\", \"encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.10.intermediate.dense.weight\", \"encoder.bert.encoder.layer.10.intermediate.dense.bias\", \"encoder.bert.encoder.layer.10.output.dense.weight\", \"encoder.bert.encoder.layer.10.output.dense.bias\", \"encoder.bert.encoder.layer.10.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.10.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.11.attention.self.query.weight\", \"encoder.bert.encoder.layer.11.attention.self.query.bias\", \"encoder.bert.encoder.layer.11.attention.self.key.weight\", \"encoder.bert.encoder.layer.11.attention.self.key.bias\", \"encoder.bert.encoder.layer.11.attention.self.value.weight\", \"encoder.bert.encoder.layer.11.attention.self.value.bias\", \"encoder.bert.encoder.layer.11.attention.output.dense.weight\", \"encoder.bert.encoder.layer.11.attention.output.dense.bias\", \"encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"encoder.bert.encoder.layer.11.intermediate.dense.weight\", \"encoder.bert.encoder.layer.11.intermediate.dense.bias\", \"encoder.bert.encoder.layer.11.output.dense.weight\", \"encoder.bert.encoder.layer.11.output.dense.bias\", \"encoder.bert.encoder.layer.11.output.LayerNorm.weight\", \"encoder.bert.encoder.layer.11.output.LayerNorm.bias\", \"encoder.bert.pooler.dense.weight\", \"encoder.bert.pooler.dense.bias\", \"encoder.classifier.weight\", \"encoder.classifier.bias\". "
     ]
    }
   ],
   "source": [
    "best_model = LSTM().to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.0005)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBKec\\Anaconda3\\envs\\opencv\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "destination_folder = '../Data/Processed'\n",
    "test_raw = pd.read_csv('../Data/test.csv')\n",
    "for i in range(16-len(test_raw)%16):\n",
    "    newRow = pd.DataFrame({\"id\": [-1], \"text\" : [\"NA\"]})\n",
    "    test_raw = test_raw.append(newRow)\n",
    "test_raw = test_raw.reindex(columns=['text','id'])\n",
    "test_raw.to_csv(destination_folder + '/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fields =[('text', text_field),('id', id_field)]\n",
    "test_data = TabularDataset(path='../Data/Processed/test.csv', fields=test_fields, format='CSV', skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator\n",
    "\n",
    "test_iter = BucketIterator(test_data, batch_size=32, sort_key=lambda x: len(x.text),\n",
    "                            device=device, sort=False, sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = evaluate_to_df(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = submission_df[submission_df['id'] != -1]\n",
    "submission_df = submission_df[['id','prediction']]\n",
    "submission_df.columns = ['id', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2231</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1221</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1606</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2478</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  target\n",
       "2231   0       1\n",
       "1221   2       0\n",
       "1606   3       0\n",
       "2478   9       1\n",
       "2630  11       1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = submission_df.sort_values('id')\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('../Data/Processed/LSTM/LSTMSubmission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
